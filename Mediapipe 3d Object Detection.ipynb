{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8SOKMf3-R4mb",
    "outputId": "ef0bbe5c-dc59-4fea-82a4-7038cdfe1117",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\users\\dhananjay\\anaconda3\\lib\\site-packages (0.8.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\dhananjay\\anaconda3\\lib\\site-packages (from mediapipe) (1.19.2)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\dhananjay\\anaconda3\\lib\\site-packages (from mediapipe) (4.5.5.64)\n",
      "Requirement already satisfied: absl-py in c:\\users\\dhananjay\\anaconda3\\lib\\site-packages (from mediapipe) (1.0.0)\n",
      "Requirement already satisfied: protobuf>=3.11.4 in c:\\users\\dhananjay\\anaconda3\\lib\\site-packages (from mediapipe) (3.19.4)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\dhananjay\\anaconda3\\lib\\site-packages (from mediapipe) (20.3.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\dhananjay\\anaconda3\\lib\\site-packages (from mediapipe) (3.3.2)\n",
      "Requirement already satisfied: six in c:\\users\\dhananjay\\anaconda3\\lib\\site-packages (from absl-py->mediapipe) (1.15.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\users\\dhananjay\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (2020.6.20)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\dhananjay\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.3.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\dhananjay\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (8.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\dhananjay\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\dhananjay\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\dhananjay\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (0.10.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "poEtrFBISODN"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import mediapipe as mp\n",
    "mp_objectron = mp.solutions.objectron\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "WXEFG8niSTst"
   },
   "source": [
    "# Mediapipe Objectron provides pre-trained models for shoe, chair, cup and camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "id": "_OkODXaSSivt",
    "outputId": "6385b457-5e85-48f4-9e55-7a5ef3e97c84"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# Read images with OpenCV.\n",
    "chair_images = {name: cv2.imread(name) for name in glob.glob(\"chair/*.png\")}\n",
    "\n",
    "# Preview the images.\n",
    "for name, image in chair_images.items():\n",
    "  print(name)   \n",
    "  cv2_imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "id": "5Bx_I8e9SpaG",
    "outputId": "524ce2aa-99d8-428a-ea46-c45221843118"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model to C:\\Users\\Dhananjay\\anaconda3\\lib\\site-packages\\mediapipe/modules/objectron/object_detection_ssd_mobilenetv2_oidv4_fp16.tflite\n",
      "Downloading model to C:\\Users\\Dhananjay\\anaconda3\\lib\\site-packages\\mediapipe/modules/objectron/object_detection_3d_sneakers.tflite\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-3acdaff3e2c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m       \u001b[1;31m# Run inference on chair images.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;31m# Convert the BGR image to RGB and process it with MediaPipe Objectron.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobjectron\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;31m# Draw box landmarks.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mediapipe\\python\\solutions\\objectron.py\u001b[0m in \u001b[0;36mprocess\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    258\u001b[0m     \"\"\"\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetected_objects\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m       \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetected_objects\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetected_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mediapipe\\python\\solution_base.py\u001b[0m in \u001b[0;36mprocess\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m    332\u001b[0m                                      data).at(self._simulated_timestamp))\n\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 334\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait_until_idle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    335\u001b[0m     \u001b[1;31m# Create a NamedTuple object where the field names are mapping to the graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m     \u001b[1;31m# output stream names.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, image = cap.read()\n",
    "\n",
    "    # BGR 2 RGB\n",
    "#     image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Flip on horizontal\n",
    "#     image = cv2.flip(image, 1)\n",
    "\n",
    "    # Set flag\n",
    "    image.flags.writeable = False\n",
    "    with mp_objectron.Objectron(\n",
    "        static_image_mode=True,\n",
    "        max_num_objects=5,\n",
    "        min_detection_confidence=0.5,\n",
    "        model_name='Shoe') as objectron: #Camera,Cup,Chair\n",
    "      # Run inference on chair images.\n",
    "        # Convert the BGR image to RGB and process it with MediaPipe Objectron.\n",
    "        results = objectron.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        # Draw box landmarks.\n",
    "#         if not results.detected_objects:          \n",
    "#           continue        \n",
    "        annotated_image = image.copy()\n",
    "        if results.detected_objects:          \n",
    "            for detected_object in results.detected_objects:\n",
    "              mp_drawing.draw_landmarks(\n",
    "                  image, detected_object.landmarks_2d, mp_objectron.BOX_CONNECTIONS)\n",
    "              mp_drawing.draw_axis(image, detected_object.rotation, detected_object.translation)\n",
    "        cv2.imshow('Hand Tracking', image)\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "mediapipe_objectron.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
